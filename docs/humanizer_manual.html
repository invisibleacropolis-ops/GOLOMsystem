<p>Humanizer System — Narrative Drivers for Events</p>
<p>Overview
The Humanizer converts structured gameplay events into human‑readable narration. It is designed to be provider‑driven so you can swap a rule‑based formatter for a local LLM later without changing game code.</p>
<p>Goals
- Deterministic, testable text during development (rule provider)
- Pluggable LLM provider for richer prose
- Stable event “driver” payloads that can be fed to LLMs</p>
<p>Architecture
- EventHumanizer (scripts/humanize/humanizer.gd)
  - Facade instantiated by the UI with a <code>services</code> reference and a provider mode.
  - Methods:
    - <code>humanize_event(evt: Dictionary) -&gt; String</code>
    - <code>humanize_move_summary(actor, steps, dest, tags) -&gt; String</code>
  - Provider selection: environment <code>HUMANIZER_PROVIDER</code> (rules | llm | llm_stub)</p>
<ul>
<li>Providers</li>
<li>Base (scripts/humanize/providers/base_provider.gd): interface</li>
<li>Rule (scripts/humanize/providers/rule_provider.gd): deterministic, readable text; supports terrain‑aware move aggregation</li>
<li>LLM Stub (scripts/humanize/providers/llm_stub_provider.gd): writes driver prompts to <code>user://humanizer_prompts.log</code> and returns simple prose for testing the integration path</li>
</ul>
<p>Driver Payloads (Examples)
1) Action (move)
{
  "type": "action",
  "actor": {"name": "Hero", "faction": "player"},
  "data": {"id": "move", "payload": [12, 7]}
}</p>
<p>2) Damage
{
  "type": "damage",
  "actor": {"name": "Hero", "faction": "player"},
  "data": {"defender": {"name": "Goblin", "faction": "enemy"}, "amount": 2}
}</p>
<p>3) Move Summary (aggregated)
{
  "type": "move_summary",
  "actor": {"name": "Hero", "faction": "player"},
  "steps": 6,
  "dest": [15, 10],
  "tags": {"grass": 4, "road": 2}
}</p>
<p>Integration Points
- Event source: RuntimeServices bridges TurnTimespace signals to EventBus (round/turn/ap/action/damage/status/reaction/battle_over).
- Consumer: EventLogUI creates EventHumanizer and routes events or aggregated move summaries to it; the returned text is appended to the log.</p>
<p>Runtime Selection
- Set <code>HUMANIZER_PROVIDER=rules</code> for deterministic rule text (default).
- Set <code>HUMANIZER_PROVIDER=llm</code> (or <code>llm_stub</code>) to enable the LLM path; with the stub, prompts are logged to <code>user://humanizer_prompts.log</code>.</p>
<p>Future LLM Addon Hook
- Implement a provider that calls your local LLM (shared memory, TCP, or Godot plugin API).
- Accept the driver payloads above, return a string. Keep responses short to preserve UI pacing.</p>
<p>Testing
- Rule provider is deterministic and suitable for CI.
- LLM stub ensures the plumbing works without a model present; inspect <code>humanizer_prompts.log</code> to validate inputs.</p>